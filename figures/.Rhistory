times_gibbs <- rep(0,num.mcmc)
samples_h_gibbs <- rep(0, num.mcmc)
for (iter in 1:num.mcmc){
xx <- x_gibbs(xx)
samples_h_gibbs[iter] <- h(xx)
times_gibbs[iter] <- Sys.time()
}
times_gibbs <- times_gibbs -  times_gibbs[1]
# plot(times_gibbs, samples_h_gibbs, type = 'l')
iter <- 1
sum1 <- 0
sum2 <- 0
m1_cumulative <- 0
m2_cumulative <- 0
gibbs_summary <- data.frame(method = name_, time = NA, mean = NA, variance = NA, ess = NA)
while( (iter + thining_size -1) < num.mcmc){
sum1 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]) + sum1
sum2 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]**2) + sum2
m1_cumulative <-  sum1 / (iter + thining_size - 1)
m2_cumulative <-  sum2 / (iter + thining_size - 1)
gibbs_summary <- rbind(gibbs_summary , data.frame(method = name_,
time = times_gibbs[iter + thining_size - 1],
mean = m1_cumulative,
variance = m2_cumulative - m1_cumulative**2,
ess = ess(samples_h_gibbs[1:iter])))
iter <- iter + thining_size
}
return(gibbs_summary[-1,])
}
test_gibbs <- generate_gibbs(10,1,h)
test_gibbs
## Figure 3 in Section 2
## author: Phyllis
## email: nju@g.harvard.edu
## created: 25-March 2020
## updated: 17-April 2020
rm(list =ls())
source("inst/0-setup.R")
library(tidyverse)
set.seed(2020)
# parameters to simualte y
N <- 100 # population size
features <- rnorm(N) # random features
beta <- runif(1)
alpha <- 1 / (1 + exp( - beta * features))
rho <- 0.8
# simulate y
xx_true <- runif(N) < alpha
ii <- sum(xx_true)
print(ii)
## simulation settings
num.sample <- 200
num.mcmc <- 10 * 10**4
num.burn <- 5000
thining_size <- floor(num.mcmc/num.sample) *2
## goal x | ii with
## two methods
## (a) single site Gibbs for x
## (b) exact for x
## compare the variance of test function h
h <- function(xx){
sum(xx[1:50])
}
print(h(xx_true))
print(h(xx))
## compute effective sample size
ess <- function(x) {
N <- length(x)
V <- map_dbl(seq_len(N - 1),
function(t) {
mean(diff(x, lag = t) ^ 2, na.rm = TRUE)
})
rho <- head_while(1 - V / var(x), ~ . > 0)
N / (1 + sum(rho))
}
x_gibbs <- function(xx){
## this gibbs should be proposing switch
## constraint is sum(xx) == y
# randomly choose two positions
locations <- sample(x = N, size = 2, replace = F)
while (xx[locations[1]] == xx[locations[2]] ) {
locations <- sample(x = N, size = 2, replace = F)
}
## if different than consider switch, must be 1-0 or 0-1
switch_probability <- ((1 - alpha[locations[1]]) * alpha[locations[2]] ) / ( ((1 - alpha[locations[1]]) * alpha[locations[2]] ) + ((1 - alpha[locations[2]]) * alpha[locations[1]] ))
if (xx[locations[2]] == 1) switch_probability <- 1 - switch_probability
if (runif(1) < switch_probability){
tmp <- xx[locations[1]]
xx[locations[1]] <- xx[locations[2]]
xx[locations[2]] <- tmp
}
return(xx)
}
generate_gibbs <- function(num.mcmc, thining_size, h, name_ ="singlesite"){
## returns summary
xx <- rep(0, N)
xx[sample(x = N, size = ii, replace = F)] <- 1
times_gibbs <- rep(0,num.mcmc)
samples_h_gibbs <- rep(0, num.mcmc)
for (iter in 1:num.mcmc){
xx <- x_gibbs(xx)
samples_h_gibbs[iter] <- h(xx)
times_gibbs[iter] <- Sys.time()
}
times_gibbs <- times_gibbs -  times_gibbs[1]
# plot(times_gibbs, samples_h_gibbs, type = 'l')
iter <- 2
sum1 <- 0
sum2 <- 0
m1_cumulative <- 0
m2_cumulative <- 0
gibbs_summary <- data.frame(method = name_, time = NA, mean = NA, variance = NA, ess = NA)
while( (iter + thining_size -1) < num.mcmc){
sum1 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]) + sum1
sum2 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]**2) + sum2
m1_cumulative <-  sum1 / (iter + thining_size - 1)
m2_cumulative <-  sum2 / (iter + thining_size - 1)
gibbs_summary <- rbind(gibbs_summary , data.frame(method = name_,
time = times_gibbs[iter + thining_size - 1],
mean = m1_cumulative,
variance = m2_cumulative - m1_cumulative**2,
ess = ess(samples_h_gibbs[1:iter])))
iter <- iter + thining_size
}
return(gibbs_summary[-1,])
}
test_gibbs <- generate_gibbs(10,1,h)
test_gibbs
## returns summary
xx <- rep(0, N)
xx[sample(x = N, size = ii, replace = F)] <- 1
times_gibbs <- rep(0,num.mcmc)
samples_h_gibbs <- rep(0, num.mcmc)
for (iter in 1:num.mcmc){
xx <- x_gibbs(xx)
samples_h_gibbs[iter] <- h(xx)
times_gibbs[iter] <- Sys.time()
}
times_gibbs <- times_gibbs -  times_gibbs[1]
# plot(times_gibbs, samples_h_gibbs, type = 'l')
iter <- 2
sum1 <- 0
sum2 <- 0
m1_cumulative <- 0
m2_cumulative <- 0
gibbs_summary <- data.frame(method = name_, time = NA, mean = NA, variance = NA, ess = NA)
name_ <- 'singlesite'
gibbs_summary <- data.frame(method = name_, time = NA, mean = NA, variance = NA, ess = NA)
while( (iter + thining_size -1) < num.mcmc){
sum1 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]) + sum1
sum2 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]**2) + sum2
m1_cumulative <-  sum1 / (iter + thining_size - 1)
m2_cumulative <-  sum2 / (iter + thining_size - 1)
gibbs_summary <- rbind(gibbs_summary , data.frame(method = name_,
time = times_gibbs[iter + thining_size - 1],
mean = m1_cumulative,
variance = m2_cumulative - m1_cumulative**2,
ess = ess(samples_h_gibbs[1:iter])))
iter <- iter + thining_size
}
ess(samples_h_gibbs[1:iter])
samples_h_gibbs[1:2]
ess(c(23,23))
# plot(times_gibbs, samples_h_gibbs, type = 'l')
iter <- 1 + thining_size
sum1 <- 0
sum2 <- 0
m1_cumulative <- 0
m2_cumulative <- 0
gibbs_summary <- data.frame(method = name_, time = NA, mean = NA, variance = NA, ess = NA)
while( (iter + thining_size -1) < num.mcmc){
sum1 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]) + sum1
sum2 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]**2) + sum2
m1_cumulative <-  sum1 / (iter + thining_size - 1)
m2_cumulative <-  sum2 / (iter + thining_size - 1)
gibbs_summary <- rbind(gibbs_summary , data.frame(method = name_,
time = times_gibbs[iter + thining_size - 1],
mean = m1_cumulative,
variance = m2_cumulative - m1_cumulative**2,
ess = ess(samples_h_gibbs[1:iter])))
iter <- iter + thining_size
}
ess(1:100)
num.mcmc
gibbs_summary
tail(gibbs_summary)
num.mcmc
num.mcmc/thining_size
## Figure 3 in Section 2
## author: Phyllis
## email: nju@g.harvard.edu
## created: 25-March 2020
## updated: 17-April 2020
rm(list =ls())
source("inst/0-setup.R")
library(tidyverse)
set.seed(2020)
# parameters to simualte y
N <- 100 # population size
features <- rnorm(N) # random features
beta <- runif(1)
alpha <- 1 / (1 + exp( - beta * features))
rho <- 0.8
# simulate y
xx_true <- runif(N) < alpha
ii <- sum(xx_true)
print(ii)
## simulation settings
num.sample <- 200
num.mcmc <- 10 * 10**4
num.burn <- 5000
thining_size <- floor(num.mcmc/num.sample) *2
## goal x | ii with
## two methods
## (a) single site Gibbs for x
## (b) exact for x
## compare the variance of test function h
h <- function(xx){
sum(xx[1:50])
}
print(h(xx_true))
print(h(xx))
## compute effective sample size
ess <- function(x) {
N <- length(x)
V <- map_dbl(seq_len(N - 1),
function(t) {
mean(diff(x, lag = t) ^ 2, na.rm = TRUE)
})
rho <- head_while(1 - V / var(x), ~ . > 0)
N / (1 + sum(rho))
}
x_gibbs <- function(xx){
## this gibbs should be proposing switch
## constraint is sum(xx) == y
# randomly choose two positions
locations <- sample(x = N, size = 2, replace = F)
while (xx[locations[1]] == xx[locations[2]] ) {
locations <- sample(x = N, size = 2, replace = F)
}
## if different than consider switch, must be 1-0 or 0-1
switch_probability <- ((1 - alpha[locations[1]]) * alpha[locations[2]] ) / ( ((1 - alpha[locations[1]]) * alpha[locations[2]] ) + ((1 - alpha[locations[2]]) * alpha[locations[1]] ))
if (xx[locations[2]] == 1) switch_probability <- 1 - switch_probability
if (runif(1) < switch_probability){
tmp <- xx[locations[1]]
xx[locations[1]] <- xx[locations[2]]
xx[locations[2]] <- tmp
}
return(xx)
}
generate_gibbs <- function(num.mcmc, thining_size, h, name_ ="singlesite"){
## returns summary
xx <- rep(0, N)
xx[sample(x = N, size = ii, replace = F)] <- 1
times_gibbs <- rep(0,num.mcmc)
samples_h_gibbs <- rep(0, num.mcmc)
for (iter in 1:num.mcmc){
xx <- x_gibbs(xx)
samples_h_gibbs[iter] <- h(xx)
times_gibbs[iter] <- Sys.time()
}
times_gibbs <- times_gibbs -  times_gibbs[1]
# plot(times_gibbs, samples_h_gibbs, type = 'l')
iter <- 1 + thining_size
sum1 <- 0
sum2 <- 0
m1_cumulative <- 0
m2_cumulative <- 0
gibbs_summary <- data.frame(method = name_, time = NA, mean = NA, variance = NA, ess = NA)
while( (iter + thining_size -1) < num.mcmc){
sum1 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]) + sum1
sum2 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]**2) + sum2
m1_cumulative <-  sum1 / (iter + thining_size - 1)
m2_cumulative <-  sum2 / (iter + thining_size - 1)
gibbs_summary <- rbind(gibbs_summary , data.frame(method = name_,
time = times_gibbs[iter + thining_size - 1],
mean = m1_cumulative,
variance = m2_cumulative - m1_cumulative**2,
ess = ess(samples_h_gibbs[1:iter])))
iter <- iter + thining_size
}
return(gibbs_summary[-1,])
}
test_gibbs <- generate_gibbs(10,1,h)
test_gibbs
times_exact <- rep(0, num.sample)
samples_h_exact <- rep(0, num.sample)
for (iter in 1:num.sample){
xx <- idcheck_sampling(h = ii, ps = alpha, n = N)
samples_h_exact[iter] <- h(xx)
times_exact[iter] <- Sys.time()
}
times_exact <- times_exact - times_exact[1]
exact_summary <- data.frame(method = 'exact', time = times_exact, mean = 0, variance = 0, ess = 1:num.sample)
exact_summary$mean <- cumsum(samples_h_exact) / c(1:num.sample)
exact_summary$variance <- cumsum(samples_h_exact**2) / c(1:num.sample) - exact_summary$mean**2
print(head(exact_summary))
results <- rbind(exact_summary,
generate_gibbs(num.mcmc = num.mcmc, thining_size = thining_size, h = h, name_ = 'gibbs1'),
generate_gibbs(num.mcmc = num.mcmc, thining_size = thining_size, h = h, name_ = 'gibbs2'))
## Figure 3 in Section 2
## author: Phyllis
## email: nju@g.harvard.edu
## created: 25-March 2020
## updated: 17-April 2020
rm(list =ls())
source("inst/0-setup.R")
library(tidyverse)
set.seed(2020)
# parameters to simualte y
N <- 100 # population size
features <- rnorm(N) # random features
beta <- runif(1)
alpha <- 1 / (1 + exp( - beta * features))
rho <- 0.8
# simulate y
xx_true <- runif(N) < alpha
ii <- sum(xx_true)
print(ii)
## simulation settings
num.sample <- 200
num.mcmc <-  10**4
num.burn <- 5000
thining_size <- floor(num.mcmc/num.sample) *2
## goal x | ii with
## two methods
## (a) single site Gibbs for x
## (b) exact for x
## compare the variance of test function h
h <- function(xx){
sum(xx[1:50])
}
print(h(xx_true))
print(h(xx))
## compute effective sample size
ess <- function(x) {
N <- length(x)
V <- map_dbl(seq_len(N - 1),
function(t) {
mean(diff(x, lag = t) ^ 2, na.rm = TRUE)
})
rho <- head_while(1 - V / var(x), ~ . > 0)
N / (1 + sum(rho))
}
x_gibbs <- function(xx){
## this gibbs should be proposing switch
## constraint is sum(xx) == y
# randomly choose two positions
locations <- sample(x = N, size = 2, replace = F)
while (xx[locations[1]] == xx[locations[2]] ) {
locations <- sample(x = N, size = 2, replace = F)
}
## if different than consider switch, must be 1-0 or 0-1
switch_probability <- ((1 - alpha[locations[1]]) * alpha[locations[2]] ) / ( ((1 - alpha[locations[1]]) * alpha[locations[2]] ) + ((1 - alpha[locations[2]]) * alpha[locations[1]] ))
if (xx[locations[2]] == 1) switch_probability <- 1 - switch_probability
if (runif(1) < switch_probability){
tmp <- xx[locations[1]]
xx[locations[1]] <- xx[locations[2]]
xx[locations[2]] <- tmp
}
return(xx)
}
generate_gibbs <- function(num.mcmc, thining_size, h, name_ ="singlesite"){
## returns summary
xx <- rep(0, N)
xx[sample(x = N, size = ii, replace = F)] <- 1
times_gibbs <- rep(0,num.mcmc)
samples_h_gibbs <- rep(0, num.mcmc)
for (iter in 1:num.mcmc){
xx <- x_gibbs(xx)
samples_h_gibbs[iter] <- h(xx)
times_gibbs[iter] <- Sys.time()
}
times_gibbs <- times_gibbs -  times_gibbs[1]
# plot(times_gibbs, samples_h_gibbs, type = 'l')
iter <- 1 + thining_size
sum1 <- 0
sum2 <- 0
m1_cumulative <- 0
m2_cumulative <- 0
gibbs_summary <- data.frame(method = name_, time = NA, mean = NA, variance = NA, ess = NA)
while( (iter + thining_size -1) < num.mcmc){
sum1 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]) + sum1
sum2 <- sum(samples_h_gibbs[iter : (iter + thining_size - 1)]**2) + sum2
m1_cumulative <-  sum1 / (iter + thining_size - 1)
m2_cumulative <-  sum2 / (iter + thining_size - 1)
gibbs_summary <- rbind(gibbs_summary , data.frame(method = name_,
time = times_gibbs[iter + thining_size - 1],
mean = m1_cumulative,
variance = m2_cumulative - m1_cumulative**2,
ess = ess(samples_h_gibbs[1:iter])))
iter <- iter + thining_size
}
return(gibbs_summary[-1,])
}
test_gibbs <- generate_gibbs(10,1,h)
test_gibbs
times_exact <- rep(0, num.sample)
samples_h_exact <- rep(0, num.sample)
for (iter in 1:num.sample){
xx <- idcheck_sampling(h = ii, ps = alpha, n = N)
samples_h_exact[iter] <- h(xx)
times_exact[iter] <- Sys.time()
}
times_exact <- times_exact - times_exact[1]
exact_summary <- data.frame(method = 'exact', time = times_exact, mean = 0, variance = 0, ess = 1:num.sample)
exact_summary$mean <- cumsum(samples_h_exact) / c(1:num.sample)
exact_summary$variance <- cumsum(samples_h_exact**2) / c(1:num.sample) - exact_summary$mean**2
print(head(exact_summary))
results <- rbind(exact_summary,
generate_gibbs(num.mcmc = num.mcmc, thining_size = thining_size, h = h, name_ = 'gibbs1'),
generate_gibbs(num.mcmc = num.mcmc, thining_size = thining_size, h = h, name_ = 'gibbs2'))
head(results)
tail(results)
p4 <- ggplot(data = results, aes(x = time, y = ess, colour = method)) + geom_line()
p4
subset(results, method == exact_summary)
subset(results, method == 'exact')
print(head(exact_summary))
exact_summary <- data.frame(method = 'exact', time = times_exact, mean = 0, variance = 0, ess = 1:num.sample)
exact_summary$mean <- cumsum(samples_h_exact) / c(1:num.sample)
exact_summary$variance <- cumsum(samples_h_exact**2) / c(1:num.sample) - exact_summary$mean**2
print(head(exact_summary))
times_exact <- rep(0, num.sample)
samples_h_exact <- rep(0, num.sample)
for (iter in 1:num.sample){
xx <- idcheck_sampling(h = ii, ps = alpha, n = N)
samples_h_exact[iter] <- h(xx)
times_exact[iter] <- Sys.time()
}
## can look at the epsilon mixing time againt n and nlogn
p0 <- ggplot(df_tau, aes(x = N, y = tau / N , colour = factor(i2n))) + geom_point(aes(shape = factor(alpha), size = 2))
p0 <- p0 + scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
p0
source("inst/0-setup.R")
unbiasedmcmc::setmytheme()
library(ggplot2)
## can look at the epsilon mixing time againt n and nlogn
p0 <- ggplot(df_tau, aes(x = N, y = tau / N , colour = factor(i2n))) + geom_point(aes(shape = factor(alpha), size = 2))
p0 <- p0 + scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
p0
ggsave("figures/epsilon_mixing_deterministic_alpha_0.png", p0,  width = 16, height = 10)
ggsave("~/Dropbox/AgentBasedModels/agents/figures/epsilon_mixing_deterministic_alpha_0.png", p0,  width = 16, height = 10)
load("~/Dropbox/AgentBasedModels/agents/figures/data_tv_bound_deterministic_alpha.RData")
rm(list =ls())
source("inst/0-setup.R")
set.seed(2020)
unbiasedmcmc::setmytheme()
load("~/Dropbox/AgentBasedModels/agents/figures/data_tv_bound_deterministic_alpha.RData")## can look at the epsilon mixing time againt n and nlogn
## tau/N vs N
p0 <- ggplot(df_tau, aes(x = N, y = tau / N , colour = factor(i2n))) + geom_point(aes(shape = factor(alpha), size = 2))
p0 <- p0 + scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
p0
# ggsave("~/Dropbox/AgentBasedModels/agents/figures/epsilon_mixing_deterministic_alpha_0.png", p0,  width = 16, height = 10)
## compare the epsilon mixing time and the fitted epsilon mixing time
p1n <- ggplot(df_tau_fitted, aes(x = N, y = tau, colour = factor(i2n), shape = factor(alpha))) +
geom_point(aes( size = 2)) +
geom_line(aes(y = fitted_tau_n), linetype = 'dashed') + ggtitle('tau vs. N') +
scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
# p1n
p1nlogn <- ggplot(df_tau_fitted, aes(x = N, y = tau, colour = factor(i2n), shape = factor(alpha))) +
geom_point(aes(size = 2)) +
geom_line(aes(y = fitted_tau_nlogn), linetype = 'dashed') + ggtitle('tau vs. NlogN') +
scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
# p1nlogn
grid.arrange(p1n, p1nlogn, nrow = 1)
g <- arrangeGrob(p1n, p1nlogn, nrow = 1)
p2 <- ggplot(df_tau_fitted, aes(x = N, y = tau, colour = factor(i2n), shape = factor(alpha))) +
geom_point(aes(size = 2)) +
geom_line(aes( y = fitted_tau_n), linetype = 'dashed') +
geom_line(aes( y = fitted_tau_nlogn)) +
scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
p2
g
g
g <- arrangeGrob(p1n, p1nlogn, nrow = 1)
grid.arrange(p1n, p1nlogn, nrow = 1)
library(ggplot2)
rm(list =ls())
source("inst/0-setup.R")
set.seed(2020)
unbiasedmcmc::setmytheme()
load("~/Dropbox/AgentBasedModels/agents/figures/data_tv_bound_deterministic_alpha.RData")## can look at the epsilon mixing time againt n and nlogn
## tau/N vs N
p0 <- ggplot(df_tau, aes(x = N, y = tau / N , colour = factor(i2n))) + geom_point(aes(shape = factor(alpha), size = 2))
p0 <- p0 + scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
p0
## compare the epsilon mixing time and the fitted epsilon mixing time
p1n <- ggplot(df_tau_fitted, aes(x = N, y = tau, colour = factor(i2n), shape = factor(alpha))) +
geom_point(aes( size = 2)) +
geom_line(aes(y = fitted_tau_n), linetype = 'dashed') + ggtitle('tau vs. N') +
scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
p1nlogn <- ggplot(df_tau_fitted, aes(x = N, y = tau, colour = factor(i2n), shape = factor(alpha))) +
geom_point(aes(size = 2)) +
geom_line(aes(y = fitted_tau_nlogn), linetype = 'dashed') + ggtitle('tau vs. NlogN') +
scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
grid.arrange(p1n, p1nlogn, nrow = 1)
g <- arrangeGrob(p1n, p1nlogn, nrow = 1)
library(ggplot2)
grid.arrange(p1n, p1nlogn, nrow = 1)
library(gridExtra)
grid.arrange(p1n, p1nlogn, nrow = 1)
g <- arrangeGrob(p1n, p1nlogn, nrow = 1)
library(gridExtra)
grid.arrange(p1n, p1nlogn, nrow = 1)
g <- arrangeGrob(p1n, p1nlogn, nrow = 1)
p2 <- ggplot(df_tau_fitted, aes(x = N, y = tau, colour = factor(i2n), shape = factor(alpha))) +
geom_point(aes(size = 2)) +
geom_line(aes( y = fitted_tau_n), linetype = 'dashed') +
geom_line(aes( y = fitted_tau_nlogn)) +
scale_color_discrete(name = 'i/N:') + scale_shape_discrete(name = 'alpha:') + scale_size_continuous(guide = FALSE)
p2
